{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Linear Regression\n",
    "\n",
    "Now, we are going to make some examples about the **Multivariate Linear Regression**. However instead of using python without \"any\" help to make our implementation, we are going to use a Python package called **SciKit Learn**.\n",
    "\n",
    "But, first let's define some notation:\n",
    "\n",
    "$x_{j}^{(i)}=$ value of feature $j$ in the $i^{th}$ training example\n",
    "$x^{(i)}=$ the input (features) of the $i^{th}$ training example\n",
    "$m=$ the number of training examples\n",
    "$n=$ the number of features\n",
    "\n",
    "The multivariable form of the hypothesis function accomodating these multiple features is as follows:\n",
    "\n",
    "$h_{\\theta}(x)=\\theta_{0}+\\theta_{1}x_{1}++\\theta_{2}x_{2}++\\theta_{3}x_{3}+ ... +\\theta_{n}x_{n}$\n",
    "\n",
    "In order to develop intuition about this function, we can think about $\\theta_{0}$ as the basic price of a house, $\\theta_{1}$ as the price per square meter, $\\theta_{2}$ as the price per floor, etc. $x_{1}$ will be the number of square meters in the house, $x_{2}$ the number of floors, etc.\n",
    "\n",
    "Using the definition of matrix multiplication, our multivariate hypothesis function can be concisely represented as:\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "\\theta_{0} & \\theta_{1} & \\ldots & \\theta_{n}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_{0} \\\\ x_{1} \\\\ \\vdots \\\\ x_{n}\n",
    "\\end{bmatrix}=\\theta^{T}x$\n",
    "\n",
    "This is a vectorization of our hypothesis function for one training example. Remember that in this case we are assuming that $x_{0}^{(i)} = 1$ for $(i \\in 1,\\ldots,m)$\n",
    "\n",
    "## Gradient Descent for Multiple Variables\n",
    "\n",
    "The gradient descent equation itself is generally the same form; we just have to repeat it for our **n** features:\n",
    "\n",
    "Repeat until convergence:{\n",
    "$$\\begin{equation}\n",
    "    \\begin{split}\n",
    "        \\theta_{0} := \\theta_{0} - \\alpha \\frac{1}{m} \\sum_{i=1}^{m}(h_{\\theta}(x^{(i)})-y^{(i)})x_{0}^{(i)} \\\\\n",
    "        \\theta_{1} := \\theta_{1} - \\alpha \\frac{1}{m} \\sum_{i=1}^{m}(h_{\\theta}(x^{(i)})-y^{(i)})x_{1}^{(i)} \\\\ \n",
    "        \\theta_{2} := \\theta_{2} - \\alpha \\frac{1}{m} \\sum_{i=1}^{m}(h_{\\theta}(x^{(i)})-y^{(i)})x_{2}^{(i)} \\\\ \n",
    "        \\ldots       \n",
    "    \\end{split}\n",
    "\\end{equation}$$\n",
    "}\n",
    "\n",
    "The equations above, could be written like:\n",
    "\n",
    "$$\\begin{equation}\n",
    "    \\begin{split}\n",
    "        \\theta_{j} := \\theta_{j} - \\alpha \\frac{1}{m} \\sum_{i=1}^{m}(h_{\\theta}(x^{(i)})-y^{(i)})x_{j}^{(i)} \\\\\n",
    "    \\end{split}\n",
    "\\end{equation} ;for j:= 0\\ldots n$$\n",
    "\n",
    "The image below summarize both gradient descent algoritms:\n",
    "\n",
    "![GDMultiOne](./images/GDOneMulti.png \"Gradient Descent Comparison\")\n",
    "\n",
    "### Scaling our algorithm\n",
    "\n",
    "Always we would like that our gradient descent algorithm converges quickly to an optimal value. However this could be difficult. If you want to test something to try to makes you algorithm converge faster you could try these options: \n",
    "\n",
    "* The first option it is called **feature scaling**\n",
    "* The second one it is called **mean normalization**\n",
    "\n",
    "In both cases the idea is to have all of our features close to the same range of values.\n",
    "\n",
    "![Scaling Algorithm](./images/scaling.png \"Scaling our algorithm\")\n",
    "\n",
    "#### Feature Scaling\n",
    "This technique involves dividing the input values by the range (i.e. the maximum value minus the minimum value) of the input variable, resulting in a new range of just 1.\n",
    "\n",
    "#### Mean Normalization\n",
    "In this case we subtract the average value for an input variable from the values for that input variable resulting in a new average value for the input variable of just zero.\n",
    "\n",
    "To implement both of these techniques, adjust your input values as shown in this formula:\n",
    "\n",
    "$$x_{i}:=\\frac{x_{i} - \\mu_{i}}{s_{i}}$$\n",
    "\n",
    "In the equation below $\\mu_{i}$ is the average of all values for feature **(i)** and $s_{i}$ is the range of values $(max-min)$, or $s_{i}$ is the standard deviation.\n",
    "\n",
    "Remember that dividing by the standard deviation of by the range gives you different results.\n",
    "\n",
    "For example, if $x_{i}$ represents housing prices with a range of 100 to 2000 and a mean value of 1000, then $x_{i}:=\\frac{price - 1000}{1900}$\n",
    "\n",
    "### Learning Rate and Debugging\n",
    "\n",
    "As you know our Gradient Descent algorithm needs to be tuned to obtain good results. It is important to make a good selection of **Learning Rate** and this is possible to make, for example, trying to plot the **Cost Function** after some iterations of the algorithm, and readjusting the **Learning Rate** parameter.\n",
    "\n",
    "![Learning Rate Debugging](./images/convergeGD.png \"Debugging\")\n",
    "\n",
    "You could create an automatic convergence test if $J(\\theta)$ decreases by less than $10^{-3}$ in one iteration. In that case you could stop the algorithm.\n",
    "\n",
    "#### How to know if Gradient Descent is working correctly ?\n",
    "\n",
    "![Gradient Descent Debugging](./images/debugGD.png \"Debugging\")\n",
    "\n",
    "For sufficiently small $\\alpha$, $J(\\theta)$ should decrease on every iteration.\n",
    "But if $\\alpha$ is too small, gradient descent can be slow to converge.\n",
    "\n",
    "To choose $\\alpha$, try $\\ldots,0.001,0.003,0.01,0.03,0.1,0.3,1\\ldots$\n",
    "\n",
    "\n",
    "### Polynomial Regression\n",
    "\n",
    "We can improve our features and the form of our hypothesis function in a couple different ways.\n",
    "\n",
    "It is possible to combine multiple features into one. For example, we can combine $x_{1}$ and $x_{2}$ into a new feature $x_{3}$ by taking $x_{1}*x_{2}$\n",
    "\n",
    "Sometimes it is possible that our hypothesis function need not be a straight line because don't fit the data well.\n",
    "\n",
    "We could change the behavior or curve of our hypothesis function by making it a quadratic, cubic or square root function (or any other form).\n",
    "\n",
    "For example, think in this hypothesis function $h_{\\theta }(x)=\\theta_{0}+\\theta_{1}x_{1}$ and look that it is possible to create additional features based on $x_{1}$, to get the quadratic function \n",
    "\n",
    "$$h_{\\theta}(x)=\\theta_{0}+\\theta_{1}x_{1}+\\theta_{2}x_{1}^{2}$$\n",
    "or the cubic function:\n",
    "\n",
    "$$h_{\\theta}(x)=\\theta_{0}+\\theta_{1}x_{1}+\\theta_{2}x_{1}^{2}+\\theta_{3}x_{1}^{3}$$\n",
    "\n",
    "In the cubic version, we have created new features $x_{2}=x_{1}^{2}$ and $x_{3}=x_{1}^{3}$\n",
    "\n",
    "Remember to take into account the use of feature scaling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
